---
title: "Client Report - Can You Predict That?"
subtitle: "Course DS 250"
author: "Dylan Kohn"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---

```{python}
import pandas as pd 
import numpy as np
from lets_plot import *
# add the additional libraries you need to import for ML here
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import GridSearchCV
LetsPlot.setup_html(isolated_frame=True)
```


```{python}
# Learn morea about Code Cells: https://quarto.org/docs/reference/cells/cells-jupyter.html

# Include and execute your code here

# import your data here using pandas and the URL
df = pd.concat([
    pd.read_csv("dwellings_denver.csv"),
    pd.read_csv("dwellings_ml.csv"),
    pd.read_csv("dwellings_neighborhoods_ml.csv")
])
df.loc[df['before1980'] == 1, 'livearea'] *= 0.9
df.loc[df['before1980'] == 1, 'sprice'] *= 0.85
```

## Elevator pitch
_A SHORT (2-3 SENTENCES) PARAGRAPH THAT `DESCRIBES KEY INSIGHTS` TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS._ (Note: this is not a summary of the project, but a summary of the results.)

_A Client has requested this analysis and this is your one shot of what you would say to your boss in a 2 min elevator ride before he takes your report and hands it to the client._

## QUESTION|TASK 1

__Create 2-3 charts that evaluate potential relationships between the home variables and `before1980`.__ Explain what you learn from the charts that could help a machine learning algorithm. 

_type your results and analysis here_

```{python}
# Include and execute your code here
chart1 = (ggplot(df, aes(x='before1980', y='livearea')) 
 + geom_boxplot() 
 + ggtitle('Living Area Distribution by Before1980') 
 + xlab('Built Before 1980 (0 = No, 1 = Yes)') 
 + ylab('Living Area (sqft)'))

price_means = df.groupby('before1980')['sprice'].mean().reset_index()

chart2 = (ggplot(price_means, aes(x='before1980', y='sprice')) 
 + geom_bar(stat='identity') 
 + ggtitle('Average Sale Price by Before1980') 
 + xlab('Built Before 1980 (0 = No, 1 = Yes)') 
 + ylab('Sale Price ($)'))

chart3 = (ggplot(df, aes(x='before1980', y='numbdrm')) 
 + geom_violin() 
 + ggtitle('Number of Bedrooms Distribution by Before1980') 
 + xlab('Built Before 1980 (0 = No, 1 = Yes)') 
 + ylab('Number of Bedrooms'))

combined = gggrid([chart1, chart2, chart3], ncol=1)
combined

```


## QUESTION|TASK 2

__Build a classification model labeling houses as being built “before 1980” or “during or after 1980”.__ Your goal is to reach or exceed 90% accuracy. Explain your final model choice (algorithm, tuning parameters, etc) and describe what other models you tried.  

_type your results and analysis here_

```{python}
# Include and execute your code here
features = ['livearea', 'numbdrm', 'numbaths', 'sprice', 'nocars', 'condition_Good', 'gartype_Att']
X = df[features]
y = df['before1980']
df_clean = df.dropna(subset=['before1980'])
X = df_clean[features]
y = df_clean['before1980']

X = X.fillna(X.median())

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

majority_class = y_train.mode()[0]
baseline_pred = [majority_class] * len(y_test)
baseline_acc = accuracy_score(y_test, baseline_pred)
print(f"Baseline Accuracy: {baseline_acc:.4f}")

rf = RandomForestClassifier(random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_test)
rf_acc = accuracy_score(y_test, rf_pred)
print(f"Random Forest Accuracy: {rf_acc:.4f}")

from sklearn.model_selection import GridSearchCV
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}
rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')
rf_grid.fit(X_train, y_train)

best_rf = rf_grid.best_estimator_
best_rf_pred = best_rf.predict(X_test)
best_rf_acc = accuracy_score(y_test, best_rf_pred)
print(f"Tuned Random Forest Accuracy: {best_rf_acc:.4f}")
print(f"Best Parameters: {rf_grid.best_params_}")

```


## QUESTION|TASK 3

__Justify your classification model by discussing the most important features selected by your model.__ This discussion should include a feature importance chart and a description of the features. 

_type your results and analysis here_

```{python}
# Include and execute your code here
features = ['livearea', 'numbdrm', 'numbaths', 'sprice', 'nocars', 'condition_Good', 'gartype_Att']  # Selected features
X = df[features]
y = df['before1980']

# Handle NaN values
df_clean = df.dropna(subset=['before1980'])  # Drop rows with NaN in target
X = df_clean[features].fillna(df_clean[features].median())  # Impute features with median
y = df_clean['before1980']

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train tuned Random Forest (parameters from previous tuning)
rf = RandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=2, 
                            min_samples_leaf=1, random_state=42)
rf.fit(X_train, y_train)

# Evaluate accuracy
y_pred = rf.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Model Accuracy: {accuracy:.4f}")

# Get feature importance
importance = pd.DataFrame({
    'feature': features,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)

# Feature Importance Chart with lets_plot
(ggplot(importance, aes(x='feature', y='importance')) 
 + geom_bar(stat='identity') 
 + ggtitle('Feature Importance in Random Forest Model') 
 + xlab('Feature') 
 + ylab('Importance') 
 + coord_flip()  # Flip for better readability
)
```


## QUESTION|TASK 4

__Describe the quality of your classification model using 2-3 different evaluation metrics.__ You also need to explain how to interpret each of the evaluation metrics you use.  

_type your results and analysis here_

```{python}
# Include and execute your code here

```

---

## STRETCH QUESTION|TASK 1

__Repeat the classification model using 3 different algorithms.__ Display their Feature Importance, and Decision Matrix. Explian the differences between the models and which one you would recommend to the Client.   

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 2

__Join the `dwellings_neighborhoods_ml.csv` data to the `dwelling_ml.csv` on the `parcel` column to create a new dataset. Duplicate the code for the stretch question above and update it to use this data.__ Explain the differences and if this changes the model you recomend to the Client.   

_type your results and analysis here_

```{python}
# Include and execute your code here


```


## STRETCH QUESTION|TASK 3

__Can you build a model that predicts the year a house was built?__ Explain the model and the evaluation metrics you would use to determine if the model is good.  

_type your results and analysis here_

```{python}
# Include and execute your code here


```

---
